<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <title>Projects | Mahmudul Haque</title>

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@300&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.0/css/bootstrap.min.css"
        crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/all.min.css"
        crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">

    <link href='https://unpkg.com/boxicons@2.1.4/css/boxicons.min.css' rel='stylesheet'>
    <!-- Option 1: Include in HTML -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons@1.3.0/font/bootstrap-icons.css">

    <!-- Custom CSS -->
    <link rel="stylesheet" href="style.css">

</head>

<body>

    <!-- Navigation Bar -->
    <nav class="navbar navbar-dark navbar-expand-sm bg-dark fixed-top">
        <div class="container">
            <a class="navbar-brand" href="/">Mahmudul Haque</a>

            <button class="navbar-toggler" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar"
                aria-expanded="false" aria-label="Toggle navigation">
                <span class="navbar-toggler-icon"></span>
            </button>
            <div class="collapse navbar-collapse" id="navbar">
                <ul class=" navbar-nav ml-auto">

                    <li class="nav-item align-content-center">
                        <a class="nav-link" href="/about">About</a>
                    </li>
                    <li class="nav-item align-content-center">
                        <a class="nav-link" href="/publications">Publications</a>
                    </li>
                    <li class="nav-item align-content-center">
                        <a class="nav-link active" href="/projects">Projects</a>
                    </li>
                    <li class="nav-item align-content-center">
                        <a class="nav-link" href="/opportunities">Opportunities</a>
                    </li>
                    <li class="nav-item align-content-center">
                        <a class="nav-link" href="/contact"> Contact</a>
                    </li>
                </ul>
            </div>
        </div>
    </nav>

    <!-- Research Section -->
    <section id="research">
        <div class="section-container">
            <h2 class="section-title">Research Projects</h2>
            <hr>
            <!-- <div class="row">
                <div class="col-md-12"> -->
            <div class="card-rows">

                <div class="card">
                    <div class="row">
                        <div class="col-md-4" style="display: flex; align-items: center; text-justify: center;">
                            <!-- <img src="img/pelvic-bone-segmentation-img.png" class="card-img" alt="..."> -->
                            <img src="img/pelvic-bone-segmentation.png" class="card-img" alt="...">
                        </div>
                        <div class="col-md-8">
                            <div class="card-body">

                                <h3 class="project-title">Pelvic Fracture and Bone Segmentation using Radiographic
                                    Images</h3>
                                <p class="project-description">The project aims to create an automatic bone segmentation
                                    model for the pelvic region using radiographic images. We utilized the Pelvic X-ray
                                    image dataset and manually annotated the images for each of the nine bones in the
                                    pelvic region using MITK Workbench. The goal of this project is to manually annotate
                                    the Sacrum (including the coccyx) (1), Ilium (2), Ischium (2), Pubis (2), and Femur
                                    (2) bones from opensource pelvic bone X-ray images, as well as to implement a
                                    machine learning model for multiclass semantic segmentation to detect and locate
                                    each of the nine pelvic bones and fractures in them. This project has potential
                                    applications in diagnosing pelvic fractures and other bone-related disorders.
                                </p>
                                <ul class="project-details">
                                    <li><strong>Duration:</strong> December 2022 - Present</li>
                                    <li><strong>Role:</strong> Research Assistant</li>
                                    <li><strong>Skills:</strong> Medical Imaging, Image Processing, Image Segmentation,
                                        Data Collection, Data Annotation</li>
                                    <li><strong>Supervisor:</strong> Dr. Saadia Binte Alam</li>
                                </ul>
                                <div class="project-links">
                                    <a href="#" class="btn btn-primary">View Project</a>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>

                <div class="card">
                    <div class="row">
                        <div class="col-md-4" style="display: flex; align-items: center; text-justify: center;">
                            <img src="img/censorship.jpg" class="card-img" alt="...">
                        </div>
                        <div class="col-md-8">
                            <div class="card-body">

                                <h3 class="project-title">Video Censorship and Rating</h3>
                                <p class="project-description">The aim of the project is to create an automated film
                                    censorship and rating (AFCR) system that recognizes, classifies, and rates sensitive
                                    audio-visual components of films using deep learning techniques. According to the
                                    project, many videos contain violence, nudity, adult content, substance misuse, or
                                    profanity, which are unacceptable for uncongenial viewers and can harm the younger
                                    generation, prompting calls for their restriction. The research examines an
                                    efficient, automated, and acceptable film content grading system based on different
                                    DL approaches. The AFCR system can assist in ensuring age-appropriate video watching
                                    and can be used for a variety of purposes ranging from content classification to
                                    real-time surveillance.
                                </p>
                                <ul class="project-details">
                                    <li><strong>Duration:</strong> January 2021 - Present</li>
                                    <li><strong>Role:</strong> Project Lead</li>
                                    <li><strong>Skills:</strong> Activity Recognition, Video Classification, Image
                                        Processing, Model Optimisation</li>
                                    <li><strong>Supervisor:</strong> Dr. Hussain Md Abu Nyeem</li>
                                </ul>
                                <div class="project-links">
                                    <a href="#" class="btn btn-primary">View Project</a>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>

                <div class="card">
                    <div class="row">
                        <div class="col-md-4" style="display: flex; align-items: center; text-justify: center;">
                            <img src="img/sign-language.jpg" class="card-img" alt="...">
                        </div>
                        <div class="col-md-8">
                            <div class="card-body">

                                <h3 class="project-title">Sign Language Translation</h3>
                                <p class="project-description">This project focuses on sign language translation (SLT)
                                    to overcome communication barriers for individuals with speech and hearing
                                    disabilities. We present a novel approach using deep learning techniques to develop
                                    a 2D convolutional neural network (CNN) model. Unlike existing models, we train our
                                    model on binary Sign Language (SL) image datasets with a preprocessing step of
                                    binarization to improve classification accuracy. Our model demonstrates impressive
                                    results, achieving high accuracy when tested on the NVIDIA Tesla K80 GPU environment
                                    (Google Colab). This research highlights the potential of our automatic SLT system,
                                    offering a promising solution for real-time translation of hand-gestured SL into
                                    natural language (NL). By leveraging computer vision and deep learning, our project
                                    contributes to improving accessibility and fostering effective communication for the
                                    hearing impaired.
                                </p>
                                <ul class="project-details">
                                    <li><strong>Duration:</strong> April 2021 - November 2021</li>
                                    <li><strong>Role:</strong> Project Lead</li>
                                    <li><strong>Skills:</strong> Object Classification, Image Processing</li>
                                    <li><strong>Supervisor:</strong> Dr. Hussain Md Abu Nyeem</li>
                                </ul>
                                <div class="project-links">
                                    <a href="#" class="btn btn-primary">View Project</a>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>

                <div class="card">
                    <div class="row">
                        <div class="col-md-4" style="display: flex; align-items: center; text-justify: center;">
                            <img src="img/surveillance.webp" class="card-img" alt="...">
                        </div>
                        <div class="col-md-8">
                            <div class="card-body">

                                <h3 class="project-title">Traffic Surveillance</h3>
                                <p class="project-description">This project introduces a sophisticated traffic
                                    surveillance system that employs a YOLOv4 object detection model to detect license
                                    plates of vehicles in Bangladesh. The model is trained and fine-tuned using
                                    convolutional neural networks (CNN) to achieve accurate license plate detection.
                                    Additionally, we leverage Tesseract OCR to recognize characters on the license
                                    plates. The system is further enhanced with a user-friendly Graphical User Interface
                                    (GUI) built using Tkinter. By combining these technologies, we enable real-time
                                    license plate detection and character recognition from video footage. Our system
                                    contributes to improved traffic monitoring, law enforcement, and security measures.
                                    The project showcases promising results, including a high mean average precision
                                    (mAP) and efficient performance on a single TESLA T4 GPU.
                                </p>
                                <ul class="project-details">
                                    <li><strong>Duration:</strong> June 2020 - December 2020</li>
                                    <li><strong>Role:</strong> Project Team Member</li>
                                    <li><strong>Skills:</strong> Object Detetction, Object
                                        Classification, OCR, Image Processing, Nodel Optimisation, Data Collection, Data
                                        Annotation</li>
                                    <li><strong>Team Lead:</strong> Md. Saif Hossain Onim</li>
                                </ul>
                                <div class="project-links">
                                    <a href="#" class="btn btn-primary">View Project</a>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>
    <div class="edit-date" id="edit-date">
        Last Edited: Loading...
    </div>
    <!-- End Research Projects Section -->

    <!-- Footer -->
    <footer class="footer-section">
        <div class="container">
            <div class="row">
                <hr>
                <div class="col-md-4">
                    <h4 class="mb-3">Useful Links</h4>
                    <ul class="list-unstyled">
                        <li><a target="_blank" href="/documents/CV.pdf">Mahmudul's CV</a></li>
                        <li><a href="/opportunities">Opportunities</a></li>
                        <li><a href="/projects">Mahmudul's Work</a></li>
                    </ul>
                </div>
                <div class="col-md-4">
                    <a href="https://info.flagcounter.com/exPH"><img
                            src="https://s11.flagcounter.com/count2/exPH/bg_343a40/txt_f7f7f7/border_343a40/columns_3/maxflags_10/viewers_0/labels_0/pageviews_0/flags_0/percent_0/"
                            alt="Flag Counter"></a>


                    <h4>Social Media</h4>
                    <div class="footer-social-links">
                        <a target="_blank" href="https://www.linkedin.com/in/mahmudeece/"><i
                                class="fab fa-linkedin"></i></a>
                        <a target="_blank" href="https://www.researchgate.net/profile/Mahmudul-Haque-4"><i
                                class="ai ai-researchgate-square ai-3x"></i></a>
                        <a target="_blank" href="https://scholar.google.com/citations?user=pn39moAAAAAJ&hl=en"><i
                                class="ai ai-google-scholar-square ai-3x"></i></a>
                    </div>

                </div>
                <div class="col-md-4">
                    <h4>Contact</h4>

                    <p><i class="bi bi-envelope"></i> mahmud.eece@gmail.com</p>
                    <p><i class="bi bi-geo-alt"></i> Dhaka, Bangladesh</p>
                    <p><i class="bi bi-phone"></i> +880 172 522 0900</p>
                </div>
            </div>
            <hr>
            <p class="text-center">&copy; 2023 Mahmudul Haque. All Rights Reserved.</p>
        </div>
    </footer>

    <!-- Bootstrap and JavaScript Libraries -->
    <script src="https://code.jquery.com/jquery-3.5.1.slim.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.9.3/dist/umd/popper.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.min.js"></script>
    <script>
        // Get the last modified date of the HTML file
        const editDate = new Date(document.lastModified);
            const editDateElement = document.getElementById('edit-date');
            
            // Format the date as desired (e.g., "September 12, 2023")
            const options = { year: 'numeric', month: 'short', day: 'numeric' };
            const formattedDate = editDate.toLocaleDateString('en-US', options);
            
            // Display the formatted date
            editDateElement.textContent = `Last Edited: ${formattedDate}`;
      </script>
</body>

</html>